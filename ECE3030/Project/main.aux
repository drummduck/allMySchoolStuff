\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces An example of an SLU framework and how a user request is broken up [3]}}{1}{figure.1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Evorus}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Evorus Architecture}{2}{subsection.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Showing the overall architecture of the Evorus system: Chatbots, workers, voting system [1]}}{3}{figure.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Choosing Chatbots Over Time}{3}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Automatic Voting}{3}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-D}}Deployment}{4}{subsection.2.4}}
\@writefile{toc}{\contentsline {section}{\numberline {III}XiaoIce}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}EQ and IQ}{5}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Framework}{5}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Results of XiaoIce}{5}{subsection.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Showing average CPS and longest conversations with versions of XiaoIce [2]}}{5}{figure.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Conversation between a user and XiaoIce [2]}}{6}{figure.4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Emotional Dialogue Generation Using Image-Grounded Language Models}{6}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Visual Conversation Agent and Image-Grounded Dialogue Generation}{7}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Understanding Images}{7}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces i) shows the text only dialogue model, while ii) shows the improved dialogue and image model [36]}}{7}{figure.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Testing and Results}{8}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The rating system for human workers with the AI responses (e.g. (3)) [36]}}{8}{figure.6}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{8}{section.5}}
\citation{huang2018evorus,shum2018eliza,perera2018multi,TalkingToSiri,AmazonRejects,SpeakMemory,Normalization,Bandits,AutoLearn,Glove,Paradise,QC,Sensitive,NIPS,Neural,Visual,Empathetic,Frames,Emotional,DeepNeural,NeuralComputation,LearningDeep,RepresentationLearning,MultiTask,Motivation,TransOnAudio,EmotionalIntelligence,PersonDigitalAssistants,Workshop,Turing,Recursive,NAACL,Emo,Spoken,ICML,Hierarchical,huber2018emotional,captioning,neuralStuff,convo,deepLearning,advance,million,mvso,facs,svm}
\bibstyle{IEEEtran}
\bibdata{bib}
\bibcite{huang2018evorus}{1}
\bibcite{shum2018eliza}{2}
\bibcite{perera2018multi}{3}
\bibcite{TalkingToSiri}{4}
\bibcite{AmazonRejects}{5}
\bibcite{SpeakMemory}{6}
\bibcite{Normalization}{7}
\bibcite{Bandits}{8}
\bibcite{AutoLearn}{9}
\bibcite{Glove}{10}
\bibcite{Paradise}{11}
\bibcite{QC}{12}
\bibcite{Sensitive}{13}
\bibcite{NIPS}{14}
\bibcite{Neural}{15}
\bibcite{Visual}{16}
\bibcite{Empathetic}{17}
\bibcite{Frames}{18}
\bibcite{Emotional}{19}
\bibcite{DeepNeural}{20}
\bibcite{NeuralComputation}{21}
\bibcite{LearningDeep}{22}
\bibcite{RepresentationLearning}{23}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Shows the human rating for responses of each given model. Sentiment and Scene and Sentiment score the highest, especially in the emotional aspect. [36]}}{9}{figure.7}}
\@writefile{toc}{\contentsline {section}{References}{9}{section*.1}}
\bibcite{MultiTask}{24}
\bibcite{Motivation}{25}
\bibcite{TransOnAudio}{26}
\bibcite{EmotionalIntelligence}{27}
\bibcite{Workshop}{28}
\bibcite{Turing}{29}
\bibcite{Recursive}{30}
\bibcite{NAACL}{31}
\bibcite{Emo}{32}
\bibcite{Spoken}{33}
\bibcite{ICML}{34}
\bibcite{Hierarchical}{35}
\bibcite{huber2018emotional}{36}
\bibcite{captioning}{37}
\bibcite{neuralStuff}{38}
\bibcite{convo}{39}
\bibcite{deepLearning}{40}
\bibcite{advance}{41}
\bibcite{million}{42}
\bibcite{mvso}{43}
\bibcite{facs}{44}
\bibcite{svm}{45}
